{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "pd.options.display.max_columns=1000\n",
    "pd.options.display.max_rows=1000\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, t_X, t_y, v_X, v_y):\n",
    "\n",
    "  param = {\"n_estimators\": trial.suggest_int(\"n_estimators:\", 100, 1000),\n",
    "           \"max_depth\": trial.suggest_int(\"max_depth\", 6, 30),\n",
    "           \"subsample\": trial.suggest_float(\"subsample\", 0.3, 1.0),\n",
    "           \"learning_rate\":  trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "           'lambda': trial.suggest_float('lambda', 1e-3, 0.1),\n",
    "           'alpha': trial.suggest_float('alpha', 1e-3, 1.0),\n",
    "           'min_child_weight': trial.suggest_int('min_child_weight', 2, 50)}\n",
    "\n",
    "  model = XGBClassifier(random_state=42,  tree_method= 'gpu_hist', **param)\n",
    "  model.fit(t_X, t_y, eval_metric='auc')\n",
    "  pred = model.predict_proba(v_X)\n",
    "  score = roc_auc_score(v_y, pred[:, 1])\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Seed '''\n",
    "seed_everything(42)\n",
    "\n",
    "''' Data Load '''\n",
    "train, test, sample_submission = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection\n",
      "Start Frequency\n",
      "Missing Value\n",
      "---------------- Start MissingValue ----------------\n",
      "Memory usage of dataframe is 7856.71 MB\n",
      "Memory usage after optimization is: 3240.89 MB\n",
      "Decreased by 58.8%\n",
      "Memory usage of dataframe is 872.97 MB\n",
      "Memory usage after optimization is: 360.10 MB\n",
      "Decreased by 58.8%\n",
      "Memory usage of dataframe is 1385.05 MB\n",
      "Memory usage after optimization is: 562.68 MB\n",
      "Decreased by 59.4%\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(columns = [\"Click\"])\n",
    "y_train = train[\"Click\"]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=42)\n",
    "\n",
    "''' preprocessing '''\n",
    "X_train, X_valid, y_train, y_valid, test = preprocessing(X_train, X_valid, y_train, y_valid, test, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F01</th>\n",
       "      <th>F02</th>\n",
       "      <th>F03</th>\n",
       "      <th>F04</th>\n",
       "      <th>F05</th>\n",
       "      <th>F06</th>\n",
       "      <th>F07</th>\n",
       "      <th>F08</th>\n",
       "      <th>F09</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "      <th>F29</th>\n",
       "      <th>F30</th>\n",
       "      <th>F31</th>\n",
       "      <th>F32</th>\n",
       "      <th>F33</th>\n",
       "      <th>F34</th>\n",
       "      <th>F35</th>\n",
       "      <th>F36</th>\n",
       "      <th>F37</th>\n",
       "      <th>F38</th>\n",
       "      <th>F39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12066756</th>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>0.169434</td>\n",
       "      <td>46.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1033</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>5812</td>\n",
       "      <td>24</td>\n",
       "      <td>514.0</td>\n",
       "      <td>24</td>\n",
       "      <td>9051</td>\n",
       "      <td>20</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>0.258057</td>\n",
       "      <td>0.239624</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27707</td>\n",
       "      <td>8191097</td>\n",
       "      <td>7577062</td>\n",
       "      <td>4311788</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7094</td>\n",
       "      <td>10062514</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.186523</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1190</td>\n",
       "      <td>0.203613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24</td>\n",
       "      <td>22758893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5255865</th>\n",
       "      <td>2211867</td>\n",
       "      <td>2369136</td>\n",
       "      <td>0.218872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2211863</td>\n",
       "      <td>4</td>\n",
       "      <td>60483</td>\n",
       "      <td>0.215942</td>\n",
       "      <td>233449</td>\n",
       "      <td>2211867</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2211867</td>\n",
       "      <td>1635381</td>\n",
       "      <td>3</td>\n",
       "      <td>0.218872</td>\n",
       "      <td>0.319092</td>\n",
       "      <td>0.199585</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9490820</td>\n",
       "      <td>8191097</td>\n",
       "      <td>7577062</td>\n",
       "      <td>12862549</td>\n",
       "      <td>7.0</td>\n",
       "      <td>227635</td>\n",
       "      <td>9490820</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.199707</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2526</td>\n",
       "      <td>0.203613</td>\n",
       "      <td>5152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2211867</td>\n",
       "      <td>22758893</td>\n",
       "      <td>3.0</td>\n",
       "      <td>238589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>558317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13191452</th>\n",
       "      <td>1111326</td>\n",
       "      <td>1111326</td>\n",
       "      <td>0.187256</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1111326</td>\n",
       "      <td>29</td>\n",
       "      <td>2270</td>\n",
       "      <td>0.215942</td>\n",
       "      <td>8186</td>\n",
       "      <td>1111326</td>\n",
       "      <td>266.0</td>\n",
       "      <td>1111326</td>\n",
       "      <td>25173</td>\n",
       "      <td>4</td>\n",
       "      <td>0.223511</td>\n",
       "      <td>0.187256</td>\n",
       "      <td>0.239624</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>436781</td>\n",
       "      <td>8191097</td>\n",
       "      <td>96765</td>\n",
       "      <td>12862549</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3539</td>\n",
       "      <td>1628146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.188721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>377455</td>\n",
       "      <td>0.318359</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1111326</td>\n",
       "      <td>22758893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24944338</th>\n",
       "      <td>2211867</td>\n",
       "      <td>2369136</td>\n",
       "      <td>0.218872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2211863</td>\n",
       "      <td>656</td>\n",
       "      <td>10499</td>\n",
       "      <td>0.242798</td>\n",
       "      <td>7501</td>\n",
       "      <td>2211867</td>\n",
       "      <td>163.0</td>\n",
       "      <td>2211867</td>\n",
       "      <td>736398</td>\n",
       "      <td>5</td>\n",
       "      <td>0.218872</td>\n",
       "      <td>0.104492</td>\n",
       "      <td>0.147705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9490820</td>\n",
       "      <td>8191097</td>\n",
       "      <td>3330771</td>\n",
       "      <td>12862549</td>\n",
       "      <td>617.0</td>\n",
       "      <td>10421</td>\n",
       "      <td>9490820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116</td>\n",
       "      <td>0.203613</td>\n",
       "      <td>33685.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2211867</td>\n",
       "      <td>2985020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9685226</th>\n",
       "      <td>166</td>\n",
       "      <td>155841</td>\n",
       "      <td>0.218872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49354</td>\n",
       "      <td>0.215942</td>\n",
       "      <td>1857</td>\n",
       "      <td>9912</td>\n",
       "      <td>183.0</td>\n",
       "      <td>781</td>\n",
       "      <td>8810</td>\n",
       "      <td>0</td>\n",
       "      <td>0.218872</td>\n",
       "      <td>0.094910</td>\n",
       "      <td>0.172729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9490820</td>\n",
       "      <td>1241173</td>\n",
       "      <td>7577062</td>\n",
       "      <td>12862549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10931</td>\n",
       "      <td>9490820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1611900</td>\n",
       "      <td>0.203613</td>\n",
       "      <td>80686.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2743</td>\n",
       "      <td>2985020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20510049</th>\n",
       "      <td>969</td>\n",
       "      <td>46107</td>\n",
       "      <td>0.169434</td>\n",
       "      <td>22.0</td>\n",
       "      <td>969</td>\n",
       "      <td>1</td>\n",
       "      <td>5908</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>429</td>\n",
       "      <td>8492</td>\n",
       "      <td>760.0</td>\n",
       "      <td>969</td>\n",
       "      <td>8051</td>\n",
       "      <td>8</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>0.409668</td>\n",
       "      <td>0.249512</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52858</td>\n",
       "      <td>2855034</td>\n",
       "      <td>3330771</td>\n",
       "      <td>12862549</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17058</td>\n",
       "      <td>10062514</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.188721</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3271</td>\n",
       "      <td>0.318359</td>\n",
       "      <td>2149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>969</td>\n",
       "      <td>22758893</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13650257</th>\n",
       "      <td>119569</td>\n",
       "      <td>610845</td>\n",
       "      <td>0.218872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119569</td>\n",
       "      <td>2</td>\n",
       "      <td>4846140</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>48255</td>\n",
       "      <td>468714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119569</td>\n",
       "      <td>57873</td>\n",
       "      <td>5</td>\n",
       "      <td>0.218872</td>\n",
       "      <td>0.155884</td>\n",
       "      <td>0.087158</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9490820</td>\n",
       "      <td>8191097</td>\n",
       "      <td>1977292</td>\n",
       "      <td>12862549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98854</td>\n",
       "      <td>9490820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583325</td>\n",
       "      <td>0.203613</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122242</td>\n",
       "      <td>22758893</td>\n",
       "      <td>5.0</td>\n",
       "      <td>57302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9074937</th>\n",
       "      <td>5289530</td>\n",
       "      <td>5305278</td>\n",
       "      <td>0.169434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5289530</td>\n",
       "      <td>0</td>\n",
       "      <td>55834</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>38570</td>\n",
       "      <td>5289530</td>\n",
       "      <td>623.0</td>\n",
       "      <td>5289530</td>\n",
       "      <td>1063558</td>\n",
       "      <td>3</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>0.144165</td>\n",
       "      <td>0.239624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5289444</td>\n",
       "      <td>273957</td>\n",
       "      <td>7577062</td>\n",
       "      <td>17046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274224</td>\n",
       "      <td>10062514</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.188721</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8586</td>\n",
       "      <td>0.151733</td>\n",
       "      <td>2867.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5289530</td>\n",
       "      <td>22758893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25352486</th>\n",
       "      <td>57699</td>\n",
       "      <td>60135</td>\n",
       "      <td>0.169434</td>\n",
       "      <td>3.0</td>\n",
       "      <td>57699</td>\n",
       "      <td>2</td>\n",
       "      <td>5699</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>4847</td>\n",
       "      <td>57699</td>\n",
       "      <td>25.0</td>\n",
       "      <td>57699</td>\n",
       "      <td>28481</td>\n",
       "      <td>0</td>\n",
       "      <td>0.223511</td>\n",
       "      <td>0.134766</td>\n",
       "      <td>0.147705</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3676</td>\n",
       "      <td>8191097</td>\n",
       "      <td>165500</td>\n",
       "      <td>48788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6774</td>\n",
       "      <td>10062514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107</td>\n",
       "      <td>0.203613</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>57699</td>\n",
       "      <td>22758893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23005038</th>\n",
       "      <td>2133</td>\n",
       "      <td>2133</td>\n",
       "      <td>0.169434</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2133</td>\n",
       "      <td>32</td>\n",
       "      <td>2330</td>\n",
       "      <td>0.178589</td>\n",
       "      <td>728</td>\n",
       "      <td>2133</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2133</td>\n",
       "      <td>14870</td>\n",
       "      <td>4</td>\n",
       "      <td>0.223511</td>\n",
       "      <td>0.292725</td>\n",
       "      <td>0.249512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>449</td>\n",
       "      <td>8191097</td>\n",
       "      <td>3330771</td>\n",
       "      <td>12862549</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4829</td>\n",
       "      <td>10062514</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.188721</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5315055</td>\n",
       "      <td>0.203613</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2133</td>\n",
       "      <td>22758893</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1172</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25744851 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              F01      F02       F03   F04      F05  F06      F07       F08  \\\n",
       "12066756       24       39  0.169434  46.0       24    0     1033  0.175781   \n",
       "5255865   2211867  2369136  0.218872   0.0  2211863    4    60483  0.215942   \n",
       "13191452  1111326  1111326  0.187256   5.0  1111326   29     2270  0.215942   \n",
       "24944338  2211867  2369136  0.218872   0.0  2211863  656    10499  0.242798   \n",
       "9685226       166   155841  0.218872   0.0        1    1    49354  0.215942   \n",
       "...           ...      ...       ...   ...      ...  ...      ...       ...   \n",
       "20510049      969    46107  0.169434  22.0      969    1     5908  0.175781   \n",
       "13650257   119569   610845  0.218872   0.0   119569    2  4846140  0.175781   \n",
       "9074937   5289530  5305278  0.169434   1.0  5289530    0    55834  0.175781   \n",
       "25352486    57699    60135  0.169434   3.0    57699    2     5699  0.175781   \n",
       "23005038     2133     2133  0.169434  31.0     2133   32     2330  0.178589   \n",
       "\n",
       "             F09      F10    F11      F12      F13  F14       F15       F16  \\\n",
       "12066756    5812       24  514.0       24     9051   20  0.167969  0.258057   \n",
       "5255865   233449  2211867   13.0  2211867  1635381    3  0.218872  0.319092   \n",
       "13191452    8186  1111326  266.0  1111326    25173    4  0.223511  0.187256   \n",
       "24944338    7501  2211867  163.0  2211867   736398    5  0.218872  0.104492   \n",
       "9685226     1857     9912  183.0      781     8810    0  0.218872  0.094910   \n",
       "...          ...      ...    ...      ...      ...  ...       ...       ...   \n",
       "20510049     429     8492  760.0      969     8051    8  0.167969  0.409668   \n",
       "13650257   48255   468714    0.0   119569    57873    5  0.218872  0.155884   \n",
       "9074937    38570  5289530  623.0  5289530  1063558    3  0.167969  0.144165   \n",
       "25352486    4847    57699   25.0    57699    28481    0  0.223511  0.134766   \n",
       "23005038     728     2133  130.0     2133    14870    4  0.223511  0.292725   \n",
       "\n",
       "               F17  F18  F19      F20      F21      F22       F23    F24  \\\n",
       "12066756  0.239624  2.0  1.0    27707  8191097  7577062   4311788    6.0   \n",
       "5255865   0.199585  3.0  0.0  9490820  8191097  7577062  12862549    7.0   \n",
       "13191452  0.239624  6.0  1.0   436781  8191097    96765  12862549    4.0   \n",
       "24944338  0.147705  1.0  0.0  9490820  8191097  3330771  12862549  617.0   \n",
       "9685226   0.172729  0.0  0.0  9490820  1241173  7577062  12862549    0.0   \n",
       "...            ...  ...  ...      ...      ...      ...       ...    ...   \n",
       "20510049  0.249512  7.0  0.0    52858  2855034  3330771  12862549   15.0   \n",
       "13650257  0.087158  5.0  0.0  9490820  8191097  1977292  12862549    0.0   \n",
       "9074937   0.239624  1.0  0.0  5289444   273957  7577062     17046    0.0   \n",
       "25352486  0.147705  3.0  2.0     3676  8191097   165500     48788    0.0   \n",
       "23005038  0.249512  1.0  1.0      449  8191097  3330771  12862549   19.0   \n",
       "\n",
       "             F25       F26   F27       F28   F29      F30       F31      F32  \\\n",
       "12066756    7094  10062514  11.0  0.186523   5.0     1190  0.203613      0.0   \n",
       "5255865   227635   9490820   7.0  0.199707   1.0     2526  0.203613   5152.0   \n",
       "13191452    3539   1628146   1.0  0.188721   1.0   377455  0.318359     23.0   \n",
       "24944338   10421   9490820   1.0  0.250000   1.0      116  0.203613  33685.0   \n",
       "9685226    10931   9490820   0.0  0.188721   0.0  1611900  0.203613  80686.0   \n",
       "...          ...       ...   ...       ...   ...      ...       ...      ...   \n",
       "20510049   17058  10062514  77.0  0.188721  16.0     3271  0.318359   2149.0   \n",
       "13650257   98854   9490820   0.0  0.188721   0.0   583325  0.203613     41.0   \n",
       "9074937   274224  10062514  22.0  0.188721   3.0     8586  0.151733   2867.0   \n",
       "25352486    6774  10062514   0.0  0.139526   0.0      107  0.203613      5.0   \n",
       "23005038    4829  10062514   6.0  0.188721   2.0  5315055  0.203613    221.0   \n",
       "\n",
       "          F33      F34       F35  F36     F37  F38     F39  \n",
       "12066756  1.0       24  22758893  1.0    9051  0.0    7094  \n",
       "5255865   0.0  2211867  22758893  3.0  238589  0.0  558317  \n",
       "13191452  3.0  1111326  22758893  0.0   25173  0.0    3539  \n",
       "24944338  0.0  2211867   2985020  1.0    7501  0.0   10445  \n",
       "9685226   0.0     2743   2985020  0.0    2409  0.0   10931  \n",
       "...       ...      ...       ...  ...     ...  ...     ...  \n",
       "20510049  0.0      969  22758893  7.0    1050  0.0   17058  \n",
       "13650257  0.0   122242  22758893  5.0   57302  0.0   98856  \n",
       "9074937   0.0  5289530  22758893  1.0   38570  0.0  274420  \n",
       "25352486  6.0    57699  22758893  0.0   28481  0.0    6781  \n",
       "23005038  1.0     2133  22758893  4.0    1172  3.0   29230  \n",
       "\n",
       "[25744851 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7817629322117648\n"
     ]
    }
   ],
   "source": [
    "param = {'max_depth': 30,\n",
    "    'num_leaves': 500,\n",
    "    'subsample': 0.9757365622458185,\n",
    "    'subsample_freq': 8,\n",
    "    'n_estimators' : 3000,\n",
    "    'min_child_samples': 136}\n",
    "model = lgb.LGBMClassifier(random_state=42, **param)\n",
    "model.fit(X_train, y_train, eval_metric='auc')\n",
    "pred_val = model.predict_proba(X_valid)\n",
    "score = roc_auc_score(y_valid, pred_val[:, 1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 30,\n",
    "    'num_leaves': 500,\n",
    "    'subsample': 0.9757365622458185,\n",
    "    'n_estimators' : 3000,\n",
    "    'min_child_samples': 500}\n",
    "\n",
    "model = XGBClassifier(random_state=42, **param)\n",
    "model.fit(X_train, y_train, eval_metric='auc')\n",
    "pred_val = model.predict_proba(X_valid)\n",
    "score = roc_auc_score(y_valid, pred_val[:, 1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns = [\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Submission '''\n",
    "sample_submission = pd.read_csv('/home/workspace/DACON/Click_predict/data/sample_submission.csv')\n",
    "sample_submission['Click'] = pred[:, 1]\n",
    "sample_submission.to_csv('lgbm_count_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nomalized X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection\n",
      "Start Frequency\n",
      "Missing Value\n",
      "---------------- Start MissingValue ----------------\n",
      "Memory usage of dataframe is 7856.71 MB\n",
      "Memory usage after optimization is: 3240.89 MB\n",
      "Decreased by 58.8%\n",
      "Memory usage of dataframe is 872.97 MB\n",
      "Memory usage after optimization is: 360.10 MB\n",
      "Decreased by 58.8%\n",
      "Memory usage of dataframe is 1385.05 MB\n",
      "Memory usage after optimization is: 562.68 MB\n",
      "Decreased by 59.4%\n",
      "0.781945008016653\n"
     ]
    }
   ],
   "source": [
    "''' Seed '''\n",
    "seed_everything(42)\n",
    "\n",
    "''' Data Load '''\n",
    "train, test, sample_submission = load_data()\n",
    "\n",
    "X_train = train.drop(columns = [\"Click\"])\n",
    "y_train = train[\"Click\"]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=42)\n",
    "\n",
    "''' preprocessing '''\n",
    "X_train, X_valid, y_train, y_valid, test = preprocessing(X_train, X_valid, y_train, y_valid, test, True) \n",
    "\n",
    "param = {'max_depth': 25,\n",
    "    'num_leaves': 306,\n",
    "    'subsample': 0.9757365622458185,\n",
    "    'subsample_freq': 8,\n",
    "    'n_estimators' : 1000,\n",
    "    'min_child_samples': 136}\n",
    "model = lgb.LGBMClassifier(random_state=42, **param)\n",
    "model.fit(X_train, y_train, eval_metric='auc')\n",
    "pred_val = model.predict_proba(X_valid)\n",
    "score = roc_auc_score(y_valid, pred_val[:, 1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781945008016653\n"
     ]
    }
   ],
   "source": [
    "score = roc_auc_score(y_valid, pred_val[:, 1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns = [\"ID\"])\n",
    "pred = model.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Submission '''\n",
    "sample_submission = pd.read_csv('/home/workspace/DACON/Click_predict/data/sample_submission.csv')\n",
    "sample_submission['Click'] = pred[:, 1]\n",
    "sample_submission.to_csv('lgbm_count_label_nomalized_x.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fold = lgb.LGBMClassifier(random_state=42, **param)\n",
    "soft_voting_value = Kfold(model_fold, 3, X_train, y_train, test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Submission '''\n",
    "sample_submission = pd.read_csv('/home/workspace/DACON/Click_predict/data/sample_submission.csv')\n",
    "sample_submission['Click'] = soft_voting_value\n",
    "sample_submission.to_csv('lgbm_kfold.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7834617635779335\n"
     ]
    }
   ],
   "source": [
    "param = {'max_depth': 30,\n",
    "    'num_leaves': 500,\n",
    "    'subsample': 0.9757365622458185,\n",
    "    'subsample_freq': 3,\n",
    "    'n_estimators' : 3000,\n",
    "    'min_child_samples': 136}\n",
    "model = lgb.LGBMClassifier(random_state=42, **param)\n",
    "model.fit(X_train, y_train, eval_metric='auc')\n",
    "pred_val = model.predict_proba(X_valid)\n",
    "score = roc_auc_score(y_valid, pred_val[:, 1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns = [\"ID\"])\n",
    "pred = model.predict_proba(test)\n",
    "\n",
    "''' Submission '''\n",
    "sample_submission = pd.read_csv('/home/workspace/DACON/Click_predict/data/sample_submission.csv')\n",
    "sample_submission['Click'] = pred[:,1]\n",
    "sample_submission.to_csv('lgbm_large_estimator.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_xgb \u001b[38;5;241m=\u001b[39m XGBClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, tree_method\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_hist\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel_xgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m pred_xgb \u001b[38;5;241m=\u001b[39m model_xgb\u001b[38;5;241m.\u001b[39mpredict_proba(X_valid)\n\u001b[1;32m      7\u001b[0m first_level \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(pred[:,\u001b[38;5;241m1\u001b[39m], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgbm\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/code_sim/lib/python3.9/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/code_sim/lib/python3.9/site-packages/xgboost/sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1491\u001b[0m (\n\u001b[1;32m   1492\u001b[0m     model,\n\u001b[1;32m   1493\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1499\u001b[0m )\n\u001b[1;32m   1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1517\u001b[0m )\n\u001b[0;32m-> 1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/code_sim/lib/python3.9/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/code_sim/lib/python3.9/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/code_sim/lib/python3.9/site-packages/xgboost/core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     _check_call(\n\u001b[0;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2054\u001b[0m     )\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_xgb = XGBClassifier(random_state=42, tree_method= 'gpu_hist', **param)\n",
    "\n",
    "model_xgb.fit(X_train, y_train, eval_metric='auc')\n",
    "\n",
    "pred_xgb = model_xgb.predict_proba(X_valid)\n",
    "\n",
    "first_level = pd.DataFrame(pred[:,1], columns=['lgbm'])\n",
    "first_level['xgb'] = pred_xgb[:,1]\n",
    "\n",
    "first_level.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "need to call fit or load_model beforehand",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_xgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m''' Submission '''\u001b[39;00m\n\u001b[1;32m      4\u001b[0m sample_submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/workspace/DACON/Click_predict/data/sample_submission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/code_sim/lib/python3.9/site-packages/xgboost/sklearn.py:1632\u001b[0m, in \u001b[0;36mXGBClassifier.predict_proba\u001b[0;34m(self, X, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1630\u001b[0m     class_prob \u001b[38;5;241m=\u001b[39m softmax(raw_predt, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m class_prob\n\u001b[0;32m-> 1632\u001b[0m class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _cls_predict_proba(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_, class_probs, np\u001b[38;5;241m.\u001b[39mvstack)\n",
      "File \u001b[0;32m~/anaconda3/envs/code_sim/lib/python3.9/site-packages/xgboost/sklearn.py:1168\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1168\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minplace_predict(\n\u001b[1;32m   1169\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   1170\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[1;32m   1171\u001b[0m             predict_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1172\u001b[0m             missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1173\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[1;32m   1174\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[1;32m   1175\u001b[0m         )\n\u001b[1;32m   1176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[1;32m   1177\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/code_sim/lib/python3.9/site-packages/xgboost/sklearn.py:725\u001b[0m, in \u001b[0;36mXGBModel.get_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__sklearn_is_fitted__():\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to call fit or load_model beforehand\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\n",
      "\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
     ]
    }
   ],
   "source": [
    "pred = model_xgb.predict_proba(test)\n",
    "\n",
    "''' Submission '''\n",
    "sample_submission = pd.read_csv('/home/workspace/DACON/Click_predict/data/sample_submission.csv')\n",
    "sample_submission['Click'] = pred[:,1]\n",
    "sample_submission.to_csv('xgb_large_estimator.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "meta_model = LinearRegression(n_jobs=-1)\n",
    "first_level.drop('label', axis=1, inplace=True)\n",
    "meta_model.fit(first_level, y_valid)\n",
    "ensemble_pred = meta_model.predict(first_level)\n",
    "sub_pred = meta_model.predict(test)\n",
    "sub_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Submission '''\n",
    "sample_submission = pd.read_csv('/home/workspace/DACON/Click_predict/data/sample_submission.csv')\n",
    "sample_submission['Click'] = sub_pred\n",
    "sample_submission.to_csv('stacking.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
