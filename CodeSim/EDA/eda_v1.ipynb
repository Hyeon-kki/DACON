{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/code_sim/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from collections import deque\n",
    "from transformers import AutoTokenizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "def preprocess_script(script):\n",
    "    new_script = deque()\n",
    "    with open(script,'r',encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        anotation_checksum = 0\n",
    "        for line in lines:\n",
    "            if (line.lstrip().startswith(\"*/\") or line.rstrip().endswith(\"*/\")):\n",
    "                anotation_checksum = 0\n",
    "                continue\n",
    "            if anotation_checksum == 1:\n",
    "                continue\n",
    "            if line.lstrip().startswith('#include'): # #include으로 시작되는 행 삭제함\n",
    "                continue\n",
    "            if line.lstrip().startswith('/*'): # 주석시작\n",
    "                if \"*/\" in line:\n",
    "                    continue\n",
    "                else:\n",
    "                    anotation_checksum = 1 \n",
    "                    continue\n",
    "\n",
    "            if line.lstrip().startswith('//'): # 주석으로 시작되는 행 삭제함\n",
    "                continue\n",
    "            line = line.rstrip()\n",
    "            if '//' in line:\n",
    "                line = line[:line.index('//')] # 주석 전까지 코드만 저장함\n",
    "            line = line.replace('\\n','') # 개행 문자를 모두 삭제함\n",
    "            line = line.replace('    ','\\t') # 공백 4칸을 tab으로 변환함\n",
    "            \n",
    "            if line.lstrip().rstrip() == '': # 전처리 후 빈 라인은 삭제함\n",
    "                continue\n",
    "            \n",
    "            new_script.append(line)\n",
    "            \n",
    "        new_script = '\\n'.join(new_script) # 개행 문자로 합침\n",
    "        new_script = re.sub('(\"\"\"[\\w\\W]*?\"\"\")', '<str>', new_script)\n",
    "        new_script = re.sub(\"('''[\\w\\W]*?''')\", '<str>', new_script)\n",
    "        new_script = re.sub('/^(http?|https?):\\/\\/([a-z0-9-]+\\.)+[a-z0-9]{2,4}.*$/', '', new_script)\n",
    "    \n",
    "    return new_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_folder = \"/home/workspace/DACON/CodeSim/Dataset/train_code\"\n",
    "problem_folders = os.listdir(code_folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:41<00:00, 11.93it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocess_scripts = []\n",
    "problem_nums = []\n",
    "problem_idx = []\n",
    "\n",
    "for problem_folder in tqdm(problem_folders):\n",
    "    scripts = os.listdir(os.path.join(code_folder, problem_folder)) # code/problem000/\n",
    "    problem_num = problem_folder # 문제 번호 폴더명\n",
    "    for script in scripts:\n",
    "        script_file = os.path.join(code_folder,problem_folder,script) # code/problem000/problem001_000.cpp\n",
    "        preprocessed_script = preprocess_script(script_file)\n",
    "        preprocess_scripts.append(preprocessed_script)\n",
    "        problem_idx.append(script)\n",
    "    # 번호 목록을 만들어서 전처리한 dataframe에 함께 넣어줌\n",
    "    problem_nums.extend([problem_num]*len(scripts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= {'code':preprocess_scripts, 'problem_num':problem_nums, 'problem_idx':problem_idx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoTokenizer로 graphcodebert 사용하도록 설정\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\n",
    "tokenizer.truncation_side = 'left'\n",
    "MAX_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [02:00<00:00, 2071.07it/s]\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "for code in tqdm(df['code']):\n",
    "    tokens.append(tokenizer.tokenize(code, max_length=MAX_LEN, truncation=True))\n",
    "\n",
    "df['tokens'] = tokens # Sample code를 Tokenization해서 tokens 컬럼에 추가\n",
    "df['len'] = df['tokens'].apply(len) # tokens의 길이를 len 컬럼에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train과 validation data set 분리\n",
    "train_df, valid_df, train_label, valid_label = train_test_split(\n",
    "        df,\n",
    "        df['problem_num'],\n",
    "        random_state=42,\n",
    "        test_size=0.1,\n",
    "        stratify=df['problem_num']\n",
    "    )\n",
    "\n",
    "train_df = train_df.reset_index(drop=True) # Reindexing\n",
    "valid_df = valid_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = train_df['code'].to_list() # code 컬럼을 list로 변환 - codes는 code가 쭉 나열된 형태임\n",
    "problems = train_df['problem_num'].unique().tolist() # 문제 번호를 중복을 제외하고 list로 변환\n",
    "problems.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_positive_pairs = []\n",
    "total_negative_pairs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:41<00:00,  4.91it/s]\n"
     ]
    }
   ],
   "source": [
    "for problem in tqdm(problems):\n",
    "    # 각각의 문제에 대한 code를 골라 정답 코드로 저장, 아닌 문제는 other_codes로 저장\n",
    "    # 이때 train_df에는 problem_num이 정렬된 상태가 아니기 때문에 index가 다를 수 있음\n",
    "    solution_codes = train_df[train_df['problem_num'] == problem]['code'].to_list()\n",
    "    other_codes = train_df[train_df['problem_num'] != problem]['code'].to_list()\n",
    "    \n",
    "    # positive_pairs 1000개 (총 500 * 1000 = 500,000개) 추출\n",
    "    # negative_pairs 1000개 (총 500 * 1000 = 500,000개) 추출\n",
    "    positive_pairs = list(combinations(solution_codes,2))\n",
    "    random.shuffle(positive_pairs)\n",
    "    positive_pairs = positive_pairs[:500]\n",
    "    random.shuffle(other_codes)\n",
    "    other_codes = other_codes[:500]\n",
    "    \n",
    "    negative_pairs = []\n",
    "    for pos_codes, others in zip(positive_pairs, other_codes):\n",
    "        negative_pairs.append((pos_codes[0], others))\n",
    "    \n",
    "    total_positive_pairs.extend(positive_pairs)\n",
    "    total_negative_pairs.extend(negative_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_positive_pairs와 negative_pairs의 정답 코드를 묶어 code1로 지정\n",
    "# total_positive_pairs와 negative_pairs의 비교 대상 코드를 묶어 code2로 지정\n",
    "# 해당 코드에 맞는 label 설정\n",
    "code1 = [code[0] for code in total_positive_pairs] + [code[0] for code in total_negative_pairs]\n",
    "code2 = [code[1] for code in total_positive_pairs] + [code[1] for code in total_negative_pairs]\n",
    "label = [1]*len(total_positive_pairs) + [0]*len(total_negative_pairs)\n",
    "\n",
    "# DataFrame으로 선언\n",
    "train_data = pd.DataFrame(data={'code1':code1, 'code2':code2, 'similar':label})\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True) # frac: 추출할 표본 비율\n",
    "train_data.to_csv('/home/workspace/DACON/CodeSim/Dataset/train_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = valid_df['code'].to_list() # code 컬럼을 list로 변환 - codes는 code가 쭉 나열된 형태임\n",
    "problems = valid_df['problem_num'].unique().tolist() # 문제 번호를 중복을 제외하고 list로 변환\n",
    "problems.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_positive_pairs = []\n",
    "total_negative_pairs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 70.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for problem in tqdm(problems):\n",
    "    # 각각의 문제에 대한 code를 골라 정답 코드로 저장, 아닌 문제는 other_codes로 저장\n",
    "    # 이때 train_df에는 problem_num이 정렬된 상태가 아니기 때문에 index가 다를 수 있음\n",
    "    solution_codes = valid_df[valid_df['problem_num'] == problem]['code'].to_list()\n",
    "    other_codes = valid_df[valid_df['problem_num'] != problem]['code'].to_list()\n",
    "    \n",
    "    # positive_pairs 100개 (총 300 * 100 = 30,000개) 추출\n",
    "    # negative_pairs 100개 (총 300 * 100 = 30,000개) 추출\n",
    "    positive_pairs = list(combinations(solution_codes,2))\n",
    "    random.shuffle(positive_pairs)\n",
    "    positive_pairs = positive_pairs[:100]\n",
    "    random.shuffle(other_codes)\n",
    "    other_codes = other_codes[:100]\n",
    "    \n",
    "    negative_pairs = []\n",
    "    for pos_codes, others in zip(positive_pairs, other_codes):\n",
    "        negative_pairs.append((pos_codes[0], others))\n",
    "    \n",
    "    total_positive_pairs.extend(positive_pairs)\n",
    "    total_negative_pairs.extend(negative_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_positive_pairs와 negative_pairs의 정답 코드를 묶어 code1로 지정\n",
    "# total_positive_pairs와 negative_pairs의 비교 대상 코드를 묶어 code2로 지정\n",
    "# 해당 코드에 맞는 label 설정\n",
    "code1 = [code[0] for code in total_positive_pairs] + [code[0] for code in total_negative_pairs]\n",
    "code2 = [code[1] for code in total_positive_pairs] + [code[1] for code in total_negative_pairs]\n",
    "label = [1]*len(total_positive_pairs) + [0]*len(total_negative_pairs)\n",
    "\n",
    "# DataFrame으로 선언\n",
    "valid_data = pd.DataFrame(data={'code1':code1, 'code2':code2, 'similar':label})\n",
    "valid_data = valid_data.sample(frac=1).reset_index(drop=True) # frac: 추출할 표본 비율\n",
    "valid_data.to_csv('/home/workspace/DACON/CodeSim/Dataset/valid_data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
